{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bPVTxb4akHi"
      },
      "source": [
        "**Vamos experimentar agora a Rede Neural Artificial?**\n",
        "Veja:\n",
        "https://scikit-learn.org/stable/modules/neural_networks_supervised.html# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "fpe0EYaXiIPm"
      },
      "outputs": [],
      "source": [
        "!pip -q install yellowbrick\n",
        "!pip -q install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "ru9xg6QIaceV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy import stats\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ler a base CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "STeZ46Y4bKfl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('breast-cancer.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Convertendo os dados nominais para dados numéricos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\eduol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "categorical_cols = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'breast', 'breast-quad', 'irradiat']\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "encoded_data = encoder.fit_transform(data[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(input_features=categorical_cols))\n",
        "\n",
        "data = pd.concat([data.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "data['Class'] = data['Class'].map({'no-recurrence-events': 0, 'recurrence-events': 1})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Eliminar redundâncias nos dados através de colunas altamente correlacionadas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       deg-malig     Class  age_30-39  age_40-49  age_50-59  \\\n",
            "deg-malig               1.000000  0.299400   0.046313   0.016290   0.023117   \n",
            "Class                   0.299400  1.000000   0.099192   0.004147   0.057214   \n",
            "age_30-39               0.046313  0.099192   1.000000   0.257143   0.269737   \n",
            "age_40-49               0.016290  0.004147   0.257143   1.000000   0.481673   \n",
            "age_50-59               0.023117  0.057214   0.269737   0.481673   1.000000   \n",
            "age_60-69               0.045018  0.001138   0.189322   0.338075   0.354632   \n",
            "age_70-79               0.109045  0.041811   0.055549   0.099195   0.104053   \n",
            "menopause_lt40          0.071934  0.003982   0.008110   0.107335   0.079082   \n",
            "menopause_premeno       0.031758  0.052386   0.340224   0.509545   0.257235   \n",
            "tumor-size_10-14        0.213471  0.188487   0.054072   0.020552   0.009931   \n",
            "tumor-size_15-19        0.069193  0.047840   0.042098   0.109112   0.001690   \n",
            "tumor-size_20-24        0.006901  0.022960   0.008151   0.104384   0.054257   \n",
            "tumor-size_25-29        0.040695  0.038140   0.021472   0.019373   0.054377   \n",
            "tumor-size_30-34        0.117266  0.134684   0.014302   0.020690   0.002543   \n",
            "tumor-size_35-39        0.134697  0.041569   0.025751   0.030867   0.018504   \n",
            "tumor-size_40-44        0.034242  0.015460   0.048686   0.054338   0.017100   \n",
            "tumor-size_45-49        0.006839  0.008140   0.039070   0.004134   0.073186   \n",
            "tumor-size_5-9          0.088719  0.077449   0.044567   0.016589   0.021605   \n",
            "tumor-size_50-54        0.011268  0.028877   0.064373   0.023629   0.014131   \n",
            "inv-nodes_12-14         0.132876  0.083233   0.039070   0.151941   0.073186   \n",
            "inv-nodes_15-17         0.155812  0.064956   0.055549   0.058415   0.050943   \n",
            "inv-nodes_24-26         0.076446  0.091089   0.022478   0.040139   0.042105   \n",
            "inv-nodes_3-5           0.117832  0.145320   0.046667   0.030159   0.001873   \n",
            "inv-nodes_6-8           0.183968  0.160084   0.082926   0.074820   0.009197   \n",
            "inv-nodes_9-11          0.090675  0.126112   0.042536   0.006019   0.025933   \n",
            "node-caps_no            0.271713  0.274964   0.001415   0.020592   0.062491   \n",
            "node-caps_yes           0.325930  0.276792   0.025263   0.007165   0.041103   \n",
            "breast_right            0.052861  0.058646   0.039441   0.103086   0.073879   \n",
            "breast-quad_central     0.073271  0.065738   0.095237   0.104159   0.026998   \n",
            "breast-quad_left_low    0.013504  0.036290   0.003333   0.025000   0.016390   \n",
            "breast-quad_left_up     0.052634  0.045711   0.049202   0.007563   0.008750   \n",
            "breast-quad_right_low   0.037217  0.031259   0.037220   0.093621   0.054905   \n",
            "breast-quad_right_up    0.020563  0.076444   0.038069   0.038069   0.001783   \n",
            "irradiat_yes            0.208099  0.193912   0.035669   0.081381   0.136102   \n",
            "\n",
            "                       age_60-69  age_70-79  menopause_lt40  \\\n",
            "deg-malig               0.045018   0.109045        0.071934   \n",
            "Class                   0.001138   0.041811        0.003982   \n",
            "age_30-39               0.189322   0.055549        0.008110   \n",
            "age_40-49               0.338075   0.099195        0.107335   \n",
            "age_50-59               0.354632   0.104053        0.079082   \n",
            "age_60-69               1.000000   0.073033        0.034264   \n",
            "age_70-79               0.073033   1.000000        0.023187   \n",
            "menopause_lt40          0.034264   0.023187        1.000000   \n",
            "menopause_premeno       0.523957   0.153735        0.166350   \n",
            "tumor-size_10-14        0.071263   0.033872        0.023961   \n",
            "tumor-size_15-19        0.086293   0.029510        0.093471   \n",
            "tumor-size_20-24        0.045284   0.003144        0.046245   \n",
            "tumor-size_25-29        0.039413   0.070624        0.076419   \n",
            "tumor-size_30-34        0.022399   0.075425        0.029537   \n",
            "tumor-size_35-39        0.097942   0.039050        0.042254   \n",
            "tumor-size_40-44        0.045481   0.140859        0.045725   \n",
            "tumor-size_45-49        0.120458   0.015072        0.016309   \n",
            "tumor-size_5-9          0.015115   0.017434        0.018865   \n",
            "tumor-size_50-54        0.074611   0.024832        0.026870   \n",
            "inv-nodes_12-14         0.051367   0.015072        0.016309   \n",
            "inv-nodes_15-17         0.073033   0.021429        0.023187   \n",
            "inv-nodes_24-26         0.118729   0.008671        0.009383   \n",
            "inv-nodes_3-5           0.021774   0.055549        0.060107   \n",
            "inv-nodes_6-8           0.022651   0.036800        0.039819   \n",
            "inv-nodes_9-11          0.094965   0.104954        0.030150   \n",
            "node-caps_no            0.036862   0.020059        0.023540   \n",
            "node-caps_yes           0.047662   0.072232        0.078159   \n",
            "breast_right            0.005152   0.039661        0.058030   \n",
            "breast-quad_central     0.006219   0.052328        0.044590   \n",
            "breast-quad_left_low    0.037366   0.065579        0.014311   \n",
            "breast-quad_left_up     0.049323   0.001802        0.029915   \n",
            "breast-quad_right_low   0.087862   0.043690        0.047940   \n",
            "breast-quad_right_up    0.043202   0.023497        0.013621   \n",
            "irradiat_yes            0.050322   0.024447        0.088465   \n",
            "\n",
            "                       menopause_premeno  tumor-size_10-14  ...  \\\n",
            "deg-malig                       0.031758          0.213471  ...   \n",
            "Class                           0.052386          0.188487  ...   \n",
            "age_30-39                       0.340224          0.054072  ...   \n",
            "age_40-49                       0.509545          0.020552  ...   \n",
            "age_50-59                       0.257235          0.009931  ...   \n",
            "age_60-69                       0.523957          0.071263  ...   \n",
            "age_70-79                       0.153735          0.033872  ...   \n",
            "menopause_lt40                  0.166350          0.023961  ...   \n",
            "menopause_premeno               1.000000          0.016146  ...   \n",
            "tumor-size_10-14                0.016146          1.000000  ...   \n",
            "tumor-size_15-19                0.062476          0.112774  ...   \n",
            "tumor-size_20-24                0.022559          0.151635  ...   \n",
            "tumor-size_25-29                0.119475          0.158936  ...   \n",
            "tumor-size_30-34                0.025252          0.169742  ...   \n",
            "tumor-size_35-39                0.085324          0.087880  ...   \n",
            "tumor-size_40-44                0.066697          0.095100  ...   \n",
            "tumor-size_45-49                0.039407          0.033918  ...   \n",
            "tumor-size_5-9                  0.005837          0.039235  ...   \n",
            "tumor-size_50-54                0.008314          0.055885  ...   \n",
            "inv-nodes_12-14                 0.029315          0.033918  ...   \n",
            "inv-nodes_15-17                 0.007174          0.048224  ...   \n",
            "inv-nodes_24-26                 0.062209          0.019514  ...   \n",
            "inv-nodes_3-5                   0.023616          0.089542  ...   \n",
            "inv-nodes_6-8                   0.056737          0.033057  ...   \n",
            "inv-nodes_9-11                  0.028786          0.062707  ...   \n",
            "node-caps_no                    0.009516          0.148652  ...   \n",
            "node-caps_yes                   0.046392          0.132905  ...   \n",
            "breast_right                    0.066228          0.026381  ...   \n",
            "breast-quad_central             0.054060          0.047631  ...   \n",
            "breast-quad_left_low            0.004428          0.029765  ...   \n",
            "breast-quad_left_up             0.057294          0.062217  ...   \n",
            "breast-quad_right_low           0.086174          0.014837  ...   \n",
            "breast-quad_right_up            0.059001          0.082151  ...   \n",
            "irradiat_yes                    0.054859          0.101079  ...   \n",
            "\n",
            "                       inv-nodes_9-11  node-caps_no  node-caps_yes  \\\n",
            "deg-malig                    0.090675      0.271713       0.325930   \n",
            "Class                        0.126112      0.274964       0.276792   \n",
            "age_30-39                    0.042536      0.001415       0.025263   \n",
            "age_40-49                    0.006019      0.020592       0.007165   \n",
            "age_50-59                    0.025933      0.062491       0.041103   \n",
            "age_60-69                    0.094965      0.036862       0.047662   \n",
            "age_70-79                    0.104954      0.020059       0.072232   \n",
            "menopause_lt40               0.030150      0.023540       0.078159   \n",
            "menopause_premeno            0.028786      0.009516       0.046392   \n",
            "tumor-size_10-14             0.062707      0.148652       0.132905   \n",
            "tumor-size_15-19             0.003041      0.046908       0.053892   \n",
            "tumor-size_20-24             0.087614      0.004170       0.018332   \n",
            "tumor-size_25-29             0.043195      0.019638       0.012911   \n",
            "tumor-size_30-34             0.088923      0.094235       0.092012   \n",
            "tumor-size_35-39             0.178521      0.092581       0.116041   \n",
            "tumor-size_40-44             0.054948      0.033906       0.055960   \n",
            "tumor-size_45-49             0.019598      0.027065       0.035684   \n",
            "tumor-size_5-9               0.022670      0.063947       0.058767   \n",
            "tumor-size_50-54             0.083147      0.010674       0.023168   \n",
            "inv-nodes_12-14              0.019598      0.109412       0.122171   \n",
            "inv-nodes_15-17              0.027864      0.214097       0.235182   \n",
            "inv-nodes_24-26              0.011275      0.110322       0.120046   \n",
            "inv-nodes_3-5                0.072232      0.327377       0.317463   \n",
            "inv-nodes_6-8                0.047851      0.361760       0.397673   \n",
            "inv-nodes_9-11               1.000000      0.308841       0.193886   \n",
            "node-caps_no                 0.308841      1.000000       0.919002   \n",
            "node-caps_yes                0.193886      0.919002       1.000000   \n",
            "breast_right                 0.012004      0.033389       0.004198   \n",
            "breast-quad_central          0.053584      0.054656       0.037561   \n",
            "breast-quad_left_low         0.033106      0.006632       0.009752   \n",
            "breast-quad_left_up          0.064668      0.012516       0.018482   \n",
            "breast-quad_right_low        0.011042      0.019044       0.009556   \n",
            "breast-quad_right_up         0.009166      0.042419       0.070010   \n",
            "irradiat_yes                 0.206678      0.370158       0.303955   \n",
            "\n",
            "                       breast_right  breast-quad_central  \\\n",
            "deg-malig                  0.052861             0.073271   \n",
            "Class                      0.058646             0.065738   \n",
            "age_30-39                  0.039441             0.095237   \n",
            "age_40-49                  0.103086             0.104159   \n",
            "age_50-59                  0.073879             0.026998   \n",
            "age_60-69                  0.005152             0.006219   \n",
            "age_70-79                  0.039661             0.052328   \n",
            "menopause_lt40             0.058030             0.044590   \n",
            "menopause_premeno          0.066228             0.054060   \n",
            "tumor-size_10-14           0.026381             0.047631   \n",
            "tumor-size_15-19           0.021588             0.034876   \n",
            "tumor-size_20-24           0.010579             0.011600   \n",
            "tumor-size_25-29           0.005384             0.067307   \n",
            "tumor-size_30-34           0.053553             0.013354   \n",
            "tumor-size_35-39           0.002755             0.075094   \n",
            "tumor-size_40-44           0.044500             0.081264   \n",
            "tumor-size_45-49           0.027895             0.102593   \n",
            "tumor-size_5-9             0.052157             0.080624   \n",
            "tumor-size_50-54           0.095685             0.047754   \n",
            "inv-nodes_12-14            0.027895             0.028984   \n",
            "inv-nodes_15-17            0.009231             0.041208   \n",
            "inv-nodes_24-26            0.055617             0.016675   \n",
            "inv-nodes_3-5              0.108425             0.025999   \n",
            "inv-nodes_6-8              0.087866             0.014074   \n",
            "inv-nodes_9-11             0.012004             0.053584   \n",
            "node-caps_no               0.033389             0.054656   \n",
            "node-caps_yes              0.004198             0.037561   \n",
            "breast_right               1.000000             0.004321   \n",
            "breast-quad_central        0.004321             1.000000   \n",
            "breast-quad_left_low       0.281404             0.222550   \n",
            "breast-quad_left_up        0.230183             0.201670   \n",
            "breast-quad_right_low      0.107272             0.085200   \n",
            "breast-quad_right_up       0.187264             0.101668   \n",
            "irradiat_yes               0.018761             0.094245   \n",
            "\n",
            "                       breast-quad_left_low  breast-quad_left_up  \\\n",
            "deg-malig                          0.013504             0.052634   \n",
            "Class                              0.036290             0.045711   \n",
            "age_30-39                          0.003333             0.049202   \n",
            "age_40-49                          0.025000             0.007563   \n",
            "age_50-59                          0.016390             0.008750   \n",
            "age_60-69                          0.037366             0.049323   \n",
            "age_70-79                          0.065579             0.001802   \n",
            "menopause_lt40                     0.014311             0.029915   \n",
            "menopause_premeno                  0.004428             0.057294   \n",
            "tumor-size_10-14                   0.029765             0.062217   \n",
            "tumor-size_15-19                   0.081190             0.052420   \n",
            "tumor-size_20-24                   0.004367             0.059151   \n",
            "tumor-size_25-29                   0.022602             0.024810   \n",
            "tumor-size_30-34                   0.089616             0.011797   \n",
            "tumor-size_35-39                   0.048838             0.013169   \n",
            "tumor-size_40-44                   0.014523             0.042641   \n",
            "tumor-size_45-49                   0.010853             0.073760   \n",
            "tumor-size_5-9                     0.032954             0.085322   \n",
            "tumor-size_50-54                   0.003353             0.057632   \n",
            "inv-nodes_12-14                    0.081397             0.001267   \n",
            "inv-nodes_15-17                    0.034718             0.001802   \n",
            "inv-nodes_24-26                    0.074927             0.042436   \n",
            "inv-nodes_3-5                      0.068333             0.004671   \n",
            "inv-nodes_6-8                      0.014029             0.055154   \n",
            "inv-nodes_9-11                     0.033106             0.064668   \n",
            "node-caps_no                       0.006632             0.012516   \n",
            "node-caps_yes                      0.009752             0.018482   \n",
            "breast_right                       0.281404             0.230183   \n",
            "breast-quad_central                0.222550             0.201670   \n",
            "breast-quad_left_low               1.000000             0.566363   \n",
            "breast-quad_left_up                0.566363             1.000000   \n",
            "breast-quad_right_low              0.239274             0.216825   \n",
            "breast-quad_right_up               0.285520             0.258733   \n",
            "irradiat_yes                       0.031167             0.033605   \n",
            "\n",
            "                       breast-quad_right_low  breast-quad_right_up  \\\n",
            "deg-malig                           0.037217              0.020563   \n",
            "Class                               0.031259              0.076444   \n",
            "age_30-39                           0.037220              0.038069   \n",
            "age_40-49                           0.093621              0.038069   \n",
            "age_50-59                           0.054905              0.001783   \n",
            "age_60-69                           0.087862              0.043202   \n",
            "age_70-79                           0.043690              0.023497   \n",
            "menopause_lt40                      0.047940              0.013621   \n",
            "menopause_premeno                   0.086174              0.059001   \n",
            "tumor-size_10-14                    0.014837              0.082151   \n",
            "tumor-size_15-19                    0.019858              0.087917   \n",
            "tumor-size_20-24                    0.039704              0.050979   \n",
            "tumor-size_25-29                    0.111767              0.034418   \n",
            "tumor-size_30-34                    0.001083              0.109585   \n",
            "tumor-size_35-39                    0.080738              0.079440   \n",
            "tumor-size_40-44                    0.087370              0.060027   \n",
            "tumor-size_45-49                    0.031162              0.070238   \n",
            "tumor-size_5-9                      0.071342              0.050182   \n",
            "tumor-size_50-54                    0.051343              0.005105   \n",
            "inv-nodes_12-14                     0.216401              0.037185   \n",
            "inv-nodes_15-17                     0.044305              0.023497   \n",
            "inv-nodes_24-26                     0.017928              0.021393   \n",
            "inv-nodes_3-5                       0.114851              0.027918   \n",
            "inv-nodes_6-8                       0.083918              0.001780   \n",
            "inv-nodes_9-11                      0.011042              0.009166   \n",
            "node-caps_no                        0.019044              0.042419   \n",
            "node-caps_yes                       0.009556              0.070010   \n",
            "breast_right                        0.107272              0.187264   \n",
            "breast-quad_central                 0.085200              0.101668   \n",
            "breast-quad_left_low                0.239274              0.285520   \n",
            "breast-quad_left_up                 0.216825              0.258733   \n",
            "breast-quad_right_low               1.000000              0.109308   \n",
            "breast-quad_right_up                0.109308              1.000000   \n",
            "irradiat_yes                        0.038323              0.047461   \n",
            "\n",
            "                       irradiat_yes  \n",
            "deg-malig                  0.208099  \n",
            "Class                      0.193912  \n",
            "age_30-39                  0.035669  \n",
            "age_40-49                  0.081381  \n",
            "age_50-59                  0.136102  \n",
            "age_60-69                  0.050322  \n",
            "age_70-79                  0.024447  \n",
            "menopause_lt40             0.088465  \n",
            "menopause_premeno          0.054859  \n",
            "tumor-size_10-14           0.101079  \n",
            "tumor-size_15-19           0.030366  \n",
            "tumor-size_20-24           0.062453  \n",
            "tumor-size_25-29           0.087322  \n",
            "tumor-size_30-34           0.034984  \n",
            "tumor-size_35-39           0.017067  \n",
            "tumor-size_40-44           0.054532  \n",
            "tumor-size_45-49           0.103732  \n",
            "tumor-size_5-9             0.003424  \n",
            "tumor-size_50-54           0.054686  \n",
            "inv-nodes_12-14            0.184349  \n",
            "inv-nodes_15-17            0.024447  \n",
            "inv-nodes_24-26            0.106060  \n",
            "inv-nodes_3-5              0.208994  \n",
            "inv-nodes_6-8              0.172224  \n",
            "inv-nodes_9-11             0.206678  \n",
            "node-caps_no               0.370158  \n",
            "node-caps_yes              0.303955  \n",
            "breast_right               0.018761  \n",
            "breast-quad_central        0.094245  \n",
            "breast-quad_left_low       0.031167  \n",
            "breast-quad_left_up        0.033605  \n",
            "breast-quad_right_low      0.038323  \n",
            "breast-quad_right_up       0.047461  \n",
            "irradiat_yes               1.000000  \n",
            "\n",
            "[34 rows x 34 columns]\n"
          ]
        }
      ],
      "source": [
        "correlation_matrix = data.corr().abs()\n",
        "upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape, dtype=bool), k=1))\n",
        "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.7)]  # Ajuste o limite de correlação conforme necessário\n",
        "data = data.drop(columns=to_drop)\n",
        "\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Balanceando os dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Antes do oversampling: Counter({0: 201, 1: 85})\n",
            "Depois do oversampling: Counter({0: 201, 1: 100})\n"
          ]
        }
      ],
      "source": [
        "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(f'Antes do oversampling: {Counter(y)}')\n",
        "print(f'Depois do oversampling: {Counter(y_resampled)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Identificar outliers e normalizar os dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "Q1 = X_treino.quantile(0.25)\n",
        "Q3 = X_treino.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "outliers = (X_treino < (Q1 - 1.5 * IQR)) | (X_treino > (Q3 + 1.5 * IQR))\n",
        "X_treino[outliers] = np.nan\n",
        "X_treino = X_treino.fillna(X_treino.median())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Padronizar os dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_treino = scaler.fit_transform(X_treino)\n",
        "X_teste = scaler.transform(X_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bCxFBVNFt22"
      },
      "source": [
        "**Vamos treinar com a rede neural?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QRptikHHepQ",
        "outputId": "f0106c94-1301-44e9-be60-e108bf82bebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.71988165\n",
            "Iteration 2, loss = 0.70561053\n",
            "Iteration 3, loss = 0.69332636\n",
            "Iteration 4, loss = 0.68170992\n",
            "Iteration 5, loss = 0.67104871\n",
            "Iteration 6, loss = 0.66144274\n",
            "Iteration 7, loss = 0.65332424\n",
            "Iteration 8, loss = 0.64454909\n",
            "Iteration 9, loss = 0.63830923\n",
            "Iteration 10, loss = 0.63206004\n",
            "Iteration 11, loss = 0.62625977\n",
            "Iteration 12, loss = 0.62118351\n",
            "Iteration 13, loss = 0.61688767\n",
            "Iteration 14, loss = 0.61300321\n",
            "Iteration 15, loss = 0.60993206\n",
            "Iteration 16, loss = 0.60657964\n",
            "Iteration 17, loss = 0.60386075\n",
            "Iteration 18, loss = 0.60152261\n",
            "Iteration 19, loss = 0.59953254\n",
            "Iteration 20, loss = 0.59755403\n",
            "Iteration 21, loss = 0.59568707\n",
            "Iteration 22, loss = 0.59420809\n",
            "Iteration 23, loss = 0.59257148\n",
            "Iteration 24, loss = 0.59141508\n",
            "Iteration 25, loss = 0.59006389\n",
            "Iteration 26, loss = 0.58904190\n",
            "Iteration 27, loss = 0.58784994\n",
            "Iteration 28, loss = 0.58672886\n",
            "Iteration 29, loss = 0.58580601\n",
            "Iteration 30, loss = 0.58474333\n",
            "Iteration 31, loss = 0.58379568\n",
            "Iteration 32, loss = 0.58284616\n",
            "Iteration 33, loss = 0.58219328\n",
            "Iteration 34, loss = 0.58129514\n",
            "Iteration 35, loss = 0.58051003\n",
            "Iteration 36, loss = 0.57995112\n",
            "Iteration 37, loss = 0.57903047\n",
            "Iteration 38, loss = 0.57840293\n",
            "Iteration 39, loss = 0.57769485\n",
            "Iteration 40, loss = 0.57690871\n",
            "Iteration 41, loss = 0.57628410\n",
            "Iteration 42, loss = 0.57559249\n",
            "Iteration 43, loss = 0.57507955\n",
            "Iteration 44, loss = 0.57441771\n",
            "Iteration 45, loss = 0.57383639\n",
            "Iteration 46, loss = 0.57328370\n",
            "Iteration 47, loss = 0.57293971\n",
            "Iteration 48, loss = 0.57238915\n",
            "Iteration 49, loss = 0.57189652\n",
            "Iteration 50, loss = 0.57144203\n",
            "Iteration 51, loss = 0.57089766\n",
            "Iteration 52, loss = 0.57041120\n",
            "Iteration 53, loss = 0.56993377\n",
            "Iteration 54, loss = 0.56950259\n",
            "Iteration 55, loss = 0.56902489\n",
            "Iteration 56, loss = 0.56858333\n",
            "Iteration 57, loss = 0.56798112\n",
            "Iteration 58, loss = 0.56748304\n",
            "Iteration 59, loss = 0.56711757\n",
            "Iteration 60, loss = 0.56658943\n",
            "Iteration 61, loss = 0.56613052\n",
            "Iteration 62, loss = 0.56576872\n",
            "Iteration 63, loss = 0.56539223\n",
            "Iteration 64, loss = 0.56496170\n",
            "Iteration 65, loss = 0.56448080\n",
            "Iteration 66, loss = 0.56411844\n",
            "Iteration 67, loss = 0.56368423\n",
            "Iteration 68, loss = 0.56319236\n",
            "Iteration 69, loss = 0.56291179\n",
            "Iteration 70, loss = 0.56252814\n",
            "Iteration 71, loss = 0.56217258\n",
            "Iteration 72, loss = 0.56176327\n",
            "Iteration 73, loss = 0.56147207\n",
            "Iteration 74, loss = 0.56118509\n",
            "Iteration 75, loss = 0.56096796\n",
            "Iteration 76, loss = 0.56058406\n",
            "Iteration 77, loss = 0.56028567\n",
            "Iteration 78, loss = 0.55983046\n",
            "Iteration 79, loss = 0.55958020\n",
            "Iteration 80, loss = 0.55918869\n",
            "Iteration 81, loss = 0.55872080\n",
            "Iteration 82, loss = 0.55840310\n",
            "Iteration 83, loss = 0.55808981\n",
            "Iteration 84, loss = 0.55761212\n",
            "Iteration 85, loss = 0.55733976\n",
            "Iteration 86, loss = 0.55705590\n",
            "Iteration 87, loss = 0.55667500\n",
            "Iteration 88, loss = 0.55632776\n",
            "Iteration 89, loss = 0.55604842\n",
            "Iteration 90, loss = 0.55573185\n",
            "Iteration 91, loss = 0.55542300\n",
            "Iteration 92, loss = 0.55514401\n",
            "Iteration 93, loss = 0.55481768\n",
            "Iteration 94, loss = 0.55440401\n",
            "Iteration 95, loss = 0.55406671\n",
            "Iteration 96, loss = 0.55370447\n",
            "Iteration 97, loss = 0.55336418\n",
            "Iteration 98, loss = 0.55311580\n",
            "Iteration 99, loss = 0.55289705\n",
            "Iteration 100, loss = 0.55266382\n",
            "Iteration 101, loss = 0.55234543\n",
            "Iteration 102, loss = 0.55217729\n",
            "Iteration 103, loss = 0.55190467\n",
            "Iteration 104, loss = 0.55158905\n",
            "Iteration 105, loss = 0.55133663\n",
            "Iteration 106, loss = 0.55106477\n",
            "Iteration 107, loss = 0.55090328\n",
            "Iteration 108, loss = 0.55056349\n",
            "Iteration 109, loss = 0.55041748\n",
            "Iteration 110, loss = 0.55026927\n",
            "Iteration 111, loss = 0.54990022\n",
            "Iteration 112, loss = 0.54967713\n",
            "Iteration 113, loss = 0.54939507\n",
            "Iteration 114, loss = 0.54905711\n",
            "Iteration 115, loss = 0.54872437\n",
            "Iteration 116, loss = 0.54834470\n",
            "Iteration 117, loss = 0.54803377\n",
            "Iteration 118, loss = 0.54769032\n",
            "Iteration 119, loss = 0.54739993\n",
            "Iteration 120, loss = 0.54719438\n",
            "Iteration 121, loss = 0.54706710\n",
            "Iteration 122, loss = 0.54688106\n",
            "Iteration 123, loss = 0.54663869\n",
            "Iteration 124, loss = 0.54644604\n",
            "Iteration 125, loss = 0.54655227\n",
            "Iteration 126, loss = 0.54637644\n",
            "Iteration 127, loss = 0.54603218\n",
            "Iteration 128, loss = 0.54582973\n",
            "Iteration 129, loss = 0.54556231\n",
            "Iteration 130, loss = 0.54537492\n",
            "Iteration 131, loss = 0.54514170\n",
            "Iteration 132, loss = 0.54480938\n",
            "Iteration 133, loss = 0.54453151\n",
            "Iteration 134, loss = 0.54425447\n",
            "Iteration 135, loss = 0.54394896\n",
            "Iteration 136, loss = 0.54363348\n",
            "Iteration 137, loss = 0.54334864\n",
            "Iteration 138, loss = 0.54298487\n",
            "Iteration 139, loss = 0.54266621\n",
            "Iteration 140, loss = 0.54253061\n",
            "Iteration 141, loss = 0.54212946\n",
            "Iteration 142, loss = 0.54193895\n",
            "Iteration 143, loss = 0.54169738\n",
            "Iteration 144, loss = 0.54148704\n",
            "Iteration 145, loss = 0.54129187\n",
            "Iteration 146, loss = 0.54105788\n",
            "Iteration 147, loss = 0.54083276\n",
            "Iteration 148, loss = 0.54066529\n",
            "Iteration 149, loss = 0.54044863\n",
            "Iteration 150, loss = 0.54019125\n",
            "Iteration 151, loss = 0.53983011\n",
            "Iteration 152, loss = 0.53962247\n",
            "Iteration 153, loss = 0.53920680\n",
            "Iteration 154, loss = 0.53905968\n",
            "Iteration 155, loss = 0.53885819\n",
            "Iteration 156, loss = 0.53863227\n",
            "Iteration 157, loss = 0.53839745\n",
            "Iteration 158, loss = 0.53812117\n",
            "Iteration 159, loss = 0.53808560\n",
            "Iteration 160, loss = 0.53799674\n",
            "Iteration 161, loss = 0.53770331\n",
            "Iteration 162, loss = 0.53751455\n",
            "Iteration 163, loss = 0.53729845\n",
            "Iteration 164, loss = 0.53697168\n",
            "Iteration 165, loss = 0.53662921\n",
            "Iteration 166, loss = 0.53638820\n",
            "Iteration 167, loss = 0.53631060\n",
            "Iteration 168, loss = 0.53609779\n",
            "Iteration 169, loss = 0.53586799\n",
            "Iteration 170, loss = 0.53561153\n",
            "Iteration 171, loss = 0.53533020\n",
            "Iteration 172, loss = 0.53505053\n",
            "Iteration 173, loss = 0.53494817\n",
            "Iteration 174, loss = 0.53467358\n",
            "Iteration 175, loss = 0.53446152\n",
            "Iteration 176, loss = 0.53424967\n",
            "Iteration 177, loss = 0.53400634\n",
            "Iteration 178, loss = 0.53389725\n",
            "Iteration 179, loss = 0.53364900\n",
            "Iteration 180, loss = 0.53332895\n",
            "Iteration 181, loss = 0.53319883\n",
            "Iteration 182, loss = 0.53307251\n",
            "Iteration 183, loss = 0.53301549\n",
            "Iteration 184, loss = 0.53277135\n",
            "Iteration 185, loss = 0.53253769\n",
            "Iteration 186, loss = 0.53248409\n",
            "Iteration 187, loss = 0.53201592\n",
            "Iteration 188, loss = 0.53178568\n",
            "Iteration 189, loss = 0.53161542\n",
            "Iteration 190, loss = 0.53131520\n",
            "Iteration 191, loss = 0.53103730\n",
            "Iteration 192, loss = 0.53081608\n",
            "Iteration 193, loss = 0.53056160\n",
            "Iteration 194, loss = 0.53035239\n",
            "Iteration 195, loss = 0.53011345\n",
            "Iteration 196, loss = 0.53000495\n",
            "Iteration 197, loss = 0.52973095\n",
            "Iteration 198, loss = 0.52961376\n",
            "Iteration 199, loss = 0.52926554\n",
            "Iteration 200, loss = 0.52919558\n",
            "Iteration 201, loss = 0.52900711\n",
            "Iteration 202, loss = 0.52871743\n",
            "Iteration 203, loss = 0.52870563\n",
            "Iteration 204, loss = 0.52836119\n",
            "Iteration 205, loss = 0.52817516\n",
            "Iteration 206, loss = 0.52793062\n",
            "Iteration 207, loss = 0.52770446\n",
            "Iteration 208, loss = 0.52753511\n",
            "Iteration 209, loss = 0.52738104\n",
            "Iteration 210, loss = 0.52749166\n",
            "Iteration 211, loss = 0.52731471\n",
            "Iteration 212, loss = 0.52711490\n",
            "Iteration 213, loss = 0.52688893\n",
            "Iteration 214, loss = 0.52666173\n",
            "Iteration 215, loss = 0.52634747\n",
            "Iteration 216, loss = 0.52618637\n",
            "Iteration 217, loss = 0.52581828\n",
            "Iteration 218, loss = 0.52561580\n",
            "Iteration 219, loss = 0.52538488\n",
            "Iteration 220, loss = 0.52506171\n",
            "Iteration 221, loss = 0.52482520\n",
            "Iteration 222, loss = 0.52474577\n",
            "Iteration 223, loss = 0.52455771\n",
            "Iteration 224, loss = 0.52448994\n",
            "Iteration 225, loss = 0.52423207\n",
            "Iteration 226, loss = 0.52416507\n",
            "Iteration 227, loss = 0.52390176\n",
            "Iteration 228, loss = 0.52360176\n",
            "Iteration 229, loss = 0.52349809\n",
            "Iteration 230, loss = 0.52308730\n",
            "Iteration 231, loss = 0.52281823\n",
            "Iteration 232, loss = 0.52258749\n",
            "Iteration 233, loss = 0.52240233\n",
            "Iteration 234, loss = 0.52213502\n",
            "Iteration 235, loss = 0.52200709\n",
            "Iteration 236, loss = 0.52174353\n",
            "Iteration 237, loss = 0.52153956\n",
            "Iteration 238, loss = 0.52145874\n",
            "Iteration 239, loss = 0.52117374\n",
            "Iteration 240, loss = 0.52095867\n",
            "Iteration 241, loss = 0.52077050\n",
            "Iteration 242, loss = 0.52056632\n",
            "Iteration 243, loss = 0.52050172\n",
            "Iteration 244, loss = 0.52040347\n",
            "Iteration 245, loss = 0.52038706\n",
            "Iteration 246, loss = 0.52014158\n",
            "Iteration 247, loss = 0.51977006\n",
            "Iteration 248, loss = 0.51982434\n",
            "Iteration 249, loss = 0.51949196\n",
            "Iteration 250, loss = 0.51921066\n",
            "Iteration 251, loss = 0.51916459\n",
            "Iteration 252, loss = 0.51871562\n",
            "Iteration 253, loss = 0.51874897\n",
            "Iteration 254, loss = 0.51857540\n",
            "Iteration 255, loss = 0.51836214\n",
            "Iteration 256, loss = 0.51813431\n",
            "Iteration 257, loss = 0.51818516\n",
            "Iteration 258, loss = 0.51790347\n",
            "Iteration 259, loss = 0.51799768\n",
            "Iteration 260, loss = 0.51762368\n",
            "Iteration 261, loss = 0.51742335\n",
            "Iteration 262, loss = 0.51723880\n",
            "Iteration 263, loss = 0.51698767\n",
            "Iteration 264, loss = 0.51696972\n",
            "Iteration 265, loss = 0.51668349\n",
            "Iteration 266, loss = 0.51665057\n",
            "Iteration 267, loss = 0.51652048\n",
            "Iteration 268, loss = 0.51631730\n",
            "Iteration 269, loss = 0.51603466\n",
            "Iteration 270, loss = 0.51585327\n",
            "Iteration 271, loss = 0.51557767\n",
            "Iteration 272, loss = 0.51559257\n",
            "Iteration 273, loss = 0.51541302\n",
            "Iteration 274, loss = 0.51520439\n",
            "Iteration 275, loss = 0.51492391\n",
            "Iteration 276, loss = 0.51486062\n",
            "Iteration 277, loss = 0.51476353\n",
            "Iteration 278, loss = 0.51445550\n",
            "Iteration 279, loss = 0.51425728\n",
            "Iteration 280, loss = 0.51403947\n",
            "Iteration 281, loss = 0.51384132\n",
            "Iteration 282, loss = 0.51370137\n",
            "Iteration 283, loss = 0.51350596\n",
            "Iteration 284, loss = 0.51334191\n",
            "Iteration 285, loss = 0.51315881\n",
            "Iteration 286, loss = 0.51294741\n",
            "Iteration 287, loss = 0.51279477\n",
            "Iteration 288, loss = 0.51272568\n",
            "Iteration 289, loss = 0.51230428\n",
            "Iteration 290, loss = 0.51235972\n",
            "Iteration 291, loss = 0.51213224\n",
            "Iteration 292, loss = 0.51187844\n",
            "Iteration 293, loss = 0.51158887\n",
            "Iteration 294, loss = 0.51157957\n",
            "Iteration 295, loss = 0.51158701\n",
            "Iteration 296, loss = 0.51129604\n",
            "Iteration 297, loss = 0.51105754\n",
            "Iteration 298, loss = 0.51091258\n",
            "Iteration 299, loss = 0.51070934\n",
            "Iteration 300, loss = 0.51051034\n",
            "Iteration 301, loss = 0.51045257\n",
            "Iteration 302, loss = 0.51026873\n",
            "Iteration 303, loss = 0.51018319\n",
            "Iteration 304, loss = 0.50994002\n",
            "Iteration 305, loss = 0.50973257\n",
            "Iteration 306, loss = 0.50953621\n",
            "Iteration 307, loss = 0.50929084\n",
            "Iteration 308, loss = 0.50917974\n",
            "Iteration 309, loss = 0.50902412\n",
            "Iteration 310, loss = 0.50886196\n",
            "Iteration 311, loss = 0.50892312\n",
            "Iteration 312, loss = 0.50916559\n",
            "Iteration 313, loss = 0.50965786\n",
            "Iteration 314, loss = 0.50985520\n",
            "Iteration 315, loss = 0.51057029\n",
            "Iteration 316, loss = 0.51066390\n",
            "Iteration 317, loss = 0.51066414\n",
            "Iteration 318, loss = 0.51054114\n",
            "Iteration 319, loss = 0.51042548\n",
            "Iteration 320, loss = 0.51017797\n",
            "Iteration 321, loss = 0.50934540\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7704918032786885"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo = MLPClassifier(max_iter=1000, verbose=True)\n",
        "modelo.fit(X_treino, y_treino)\n",
        "\n",
        "previsoes = modelo.predict(X_teste)\n",
        "accuracy_score(y_teste,previsoes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ajuste dos hiperparâmetros automaticamente**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores Hiperparâmetros:\n",
            "{'activation': 'logistic', 'hidden_layer_sizes': (10,), 'max_iter': 1000, 'solver': 'lbfgs', 'tol': 0.01, 'verbose': False}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'max_iter': [500, 1000, 1500],  # Número máximo de iterações\n",
        "    'verbose': [True, False],  # Exibir informações de depuração\n",
        "    'tol': [1e-4, 1e-3, 1e-2],  # Tolerância para parar o treinamento\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],  # Otimizador\n",
        "    'activation': ['logistic', 'tanh', 'relu'],  # Função de ativação\n",
        "    'hidden_layer_sizes': [(5,), (10,), (5, 5), (10, 10), (10, 5, 2)],  # Topologias da rede\n",
        "}\n",
        "\n",
        "modelo = MLPClassifier()\n",
        "scoring = make_scorer(accuracy_score)\n",
        "\n",
        "grid_search = GridSearchCV(modelo, param_grid, cv=5, scoring=scoring, n_jobs=-1)\n",
        "grid_search.fit(X_treino, y_treino)\n",
        "\n",
        "print(\"Melhores Hiperparâmetros:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PQZVMhEJXOC"
      },
      "source": [
        "**Modelo com os melhores parâmetros identificados pelo GSCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Q1RssrJU9z",
        "outputId": "802b6904-3a64-4a71-fd3b-221c672f3524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia do Melhor Modelo: 0.7704918032786885\n"
          ]
        }
      ],
      "source": [
        "melhor_modelo = grid_search.best_estimator_\n",
        "previsoes = melhor_modelo.predict(X_teste)\n",
        "acuracia = accuracy_score(y_teste, previsoes)\n",
        "\n",
        "print(f'Acurácia do Melhor Modelo: {acuracia}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-S4o3IczVP"
      },
      "source": [
        "\n",
        "\n",
        "> **Vamos testar o modelo?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "1q9nsbSjdu23"
      },
      "outputs": [],
      "source": [
        "previsoes = melhor_modelo.predict(X_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0PlSJE8fAUL",
        "outputId": "501c2371-84dd-4c64-f216-be2b03707888"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "previsoes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjWziqc5fV8m"
      },
      "source": [
        "\n",
        "\n",
        "> **Será se o modelo acertou?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q92H3KOtfN5E",
        "outputId": "864bf803-aaec-436b-ee87-2bd4956fc72e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "177    1\n",
              "289    1\n",
              "228    0\n",
              "198    0\n",
              "60     1\n",
              "      ..\n",
              "234    0\n",
              "296    1\n",
              "281    0\n",
              "285    0\n",
              "182    0\n",
              "Name: Class, Length: 61, dtype: int64"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ9MxYOIfmwv",
        "outputId": "d81573e1-45aa-4ea6-d922-c25e1a623343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7704918032786885"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_teste,previsoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3D5bvushr9W",
        "outputId": "45328eb3-d2be-4d4c-c5e1-248e262d7d9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[36,  4],\n",
              "       [10, 11]], dtype=int64)"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_teste, previsoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "wX15YT-7j-c9",
        "outputId": "db8b53f9-e72b-4257-c955-a229ab056d41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\eduol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7868852459016393"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = ConfusionMatrix(modelo)\n",
        "cm.fit(X_treino, y_treino)\n",
        "cm.score(X_teste, y_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIixOPw1kw-z",
        "outputId": "5b4735c0-0e3f-4981-b422-f4a5d25f5c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84        40\n",
            "           1       0.73      0.52      0.61        21\n",
            "\n",
            "    accuracy                           0.77        61\n",
            "   macro avg       0.76      0.71      0.72        61\n",
            "weighted avg       0.77      0.77      0.76        61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_teste, previsoes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csRtFY7lKr0N"
      },
      "source": [
        "**Veja como implementar o backpropagation em python:**\n",
        "https://www.askpython.com/python/examples/backpropagation-in-python\n",
        "https://www.deeplearningbook.com.br/algoritmo-backpropagation-em-python/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
